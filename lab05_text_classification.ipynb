{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lab uses the [20 Newsgroups dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html?highlight=newsgroup#sklearn.datasets.fetch_20newsgroups)\n",
    "directly available in Scikit-Learn. It comprises around 18,000 newsgroups posts spread across 20 different news classes.\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import processing as pp  # local module\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetch_20newsgroups(subset='all', shuffle=True,\n",
    "                          remove=('headers', 'footers', 'quotes'))\n",
    "data_labels_map = dict(enumerate(data.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18846, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Target Label</th>\n",
       "      <th>Target Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\nI am sure some bashers of Pens fans are pr...</td>\n",
       "      <td>10</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My brother is in the market for a high-perform...</td>\n",
       "      <td>3</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n\\n\\n\\tFinally you said what you dream abou...</td>\n",
       "      <td>17</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nThink!\\n\\nIt's the SCSI card doing the DMA t...</td>\n",
       "      <td>3</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1)    I have an old Jasmine drive which I cann...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\\n\\nBack in high school I worked as a lab assi...</td>\n",
       "      <td>12</td>\n",
       "      <td>sci.electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\\n\\nAE is in Dallas...try 214/241-6060 or 214/...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\\n[stuff deleted]\\n\\nOk, here's the solution t...</td>\n",
       "      <td>10</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\\n\\n\\nYeah, it's the second one.  And I believ...</td>\n",
       "      <td>10</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\\nIf a Christian means someone who believes in...</td>\n",
       "      <td>19</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article  Target Label  \\\n",
       "0  \\n\\nI am sure some bashers of Pens fans are pr...            10   \n",
       "1  My brother is in the market for a high-perform...             3   \n",
       "2  \\n\\n\\n\\n\\tFinally you said what you dream abou...            17   \n",
       "3  \\nThink!\\n\\nIt's the SCSI card doing the DMA t...             3   \n",
       "4  1)    I have an old Jasmine drive which I cann...             4   \n",
       "5  \\n\\nBack in high school I worked as a lab assi...            12   \n",
       "6  \\n\\nAE is in Dallas...try 214/241-6060 or 214/...             4   \n",
       "7  \\n[stuff deleted]\\n\\nOk, here's the solution t...            10   \n",
       "8  \\n\\n\\nYeah, it's the second one.  And I believ...            10   \n",
       "9  \\nIf a Christian means someone who believes in...            19   \n",
       "\n",
       "                Target Name  \n",
       "0          rec.sport.hockey  \n",
       "1  comp.sys.ibm.pc.hardware  \n",
       "2     talk.politics.mideast  \n",
       "3  comp.sys.ibm.pc.hardware  \n",
       "4     comp.sys.mac.hardware  \n",
       "5           sci.electronics  \n",
       "6     comp.sys.mac.hardware  \n",
       "7          rec.sport.hockey  \n",
       "8          rec.sport.hockey  \n",
       "9        talk.religion.misc  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus, target_labels, target_names = (data.data, data.target, \n",
    "                                       [data_labels_map[label] for label in data.target])\n",
    "data_df = pd.DataFrame({'Article': corpus, 'Target Label': target_labels,\n",
    "'Target Name': target_names})\n",
    "\n",
    "print(data_df.shape)\n",
    "data_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article         \\n\\nI am sure some bashers of Pens fans are pr...\n",
      "Target Label                                                   10\n",
      "Target Name                                      rec.sport.hockey\n",
      "Name: 0, dtype: object\n",
      "\n",
      "\n",
      "I am sure some bashers of Pens fans are pretty confused about the lack\n",
      "of any kind of posts about the recent Pens massacre of the Devils. Actually,\n",
      "I am  bit puzzled too and a bit relieved. However, I am going to put an end\n",
      "to non-PIttsburghers' relief with a bit of praise for the Pens. Man, they\n",
      "are killing those Devils worse than I thought. Jagr just showed you why\n",
      "he is much better than his regular season stats. He is also a lot\n",
      "fo fun to watch in the playoffs. Bowman should let JAgr have a lot of\n",
      "fun in the next couple of games since the Pens are going to beat the pulp out of Jersey anyway. I was very disappointed not to see the Islanders lose the final\n",
      "regular season game.          PENS RULE!!!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data_df.iloc[0])\n",
    "print(data_df.iloc[0].Article)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of empty documents = 515 out of 18846 documents\n"
     ]
    }
   ],
   "source": [
    "# How many records are empty?\n",
    "total_nulls = data_df[data_df.Article.str.strip() == \"\"].shape[0]\n",
    "\n",
    "print(\"Total number of empty documents = {} out of {} documents\".format(\n",
    "            total_nulls, data_df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18331, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the empty records\n",
    "data_df = data_df[~(data_df.Article.str.strip() == \"\")]\n",
    "data_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "norm_corpus = pp.normalize_corpus(corpus=data_df['Article'], html_stripping=True, contraction_expansion=True,\n",
    "                     accented_char_removal=True, text_lower_case=True, \n",
    "                     text_lemmatization=False, special_char_removal=True, \n",
    "                     stopword_removal=True)\n",
    "    \n",
    "data_df['Clean Article'] = norm_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data splitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14664,), (3667,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_corpus, test_corpus, train_label_nums, test_label_nums, train_label_names, test_label_names = train_test_split(np.array(data_df['Clean Article']),\n",
    "                                                                                                                     np.array(data_df['Target Label']),\n",
    "                                                                                                                     np.array(data_df['Target Name']),\n",
    "                                                                                                                     stratify=data_df['Target Label'],\n",
    "                                                                                                                     test_size=0.20, random_state=42)\n",
    "train_corpus.shape, test_corpus.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building and Evaluating Our Text Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the following workflows to build our text classifiers.\n",
    "- Traditional feature representation (BOW, TF-IDF) and classification models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words Features with Classification Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s start by using a basic Bag of Words, the term frequency-based feature engineering\n",
    "model, to extract features from our train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build BOW features on train articles\n",
    "cv = CountVectorizer(binary=False, min_df=0.0, max_df=1.0)\n",
    "cv_train_features = cv.fit_transform(train_corpus)\n",
    "\n",
    "# transform test articles into features\n",
    "cv_test_features = cv.transform(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW model:> Train features shape: (14664, 125133)  Test features shape: (3667, 125133)\n"
     ]
    }
   ],
   "source": [
    "print('BOW model:> Train features shape:', cv_train_features.shape,' Test features shape:', cv_test_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now build several classifiers on these features using the training data and test\n",
    "their performance on the test dataset using all the classification models we discussed\n",
    "earlier. We also check model accuracies using five-fold cross validation just to see if\n",
    "the model performs consistently across the validation folds of data (we use this same\n",
    "strategy to tune the models later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Accuracy: 0.8434260774686306\n",
      "Test Accuracy: 0.7022088901008999\n"
     ]
    }
   ],
   "source": [
    "# Naïve Bayes Classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB(alpha=1)\n",
    "mnb.fit(cv_train_features, train_label_names)\n",
    "\n",
    "mnb_bow_train_scores = mnb.score(cv_train_features, train_label_names)\n",
    "print('train Accuracy:', mnb_bow_train_scores)\n",
    "\n",
    "mnb_bow_test_scores = mnb.score(cv_test_features, test_label_names)\n",
    "print('Test Accuracy:', mnb_bow_test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.997545008183306\n",
      "Test Accuracy: 0.6686664848650122\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machines\n",
    "from sklearn.svm import LinearSVC\n",
    "svm = LinearSVC(penalty='l2', C=1, random_state=42)\n",
    "svm.fit(cv_train_features, train_label_names)\n",
    "\n",
    "svm_bow_train_scores = svm.score(cv_train_features, train_label_names)\n",
    "print('Train Accuracy:', svm_bow_train_scores)\n",
    "\n",
    "svm_bow_test_scores = svm.score(cv_test_features, test_label_names)\n",
    "print('Test Accuracy:', svm_bow_test_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF Features with Classification Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use TF-IDF features to train our classification models. Assuming TF-IDF weighs\n",
    "down unimportant features, we might get better performing models. Let’s test our\n",
    "assumption!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF model:> Train features shape: (14664, 125133)  Test features shape: (3667, 125133)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# build BOW features on train articles\n",
    "tv = TfidfVectorizer(use_idf=True, min_df=0.0, max_df=1.0)\n",
    "tv_train_features = tv.fit_transform(train_corpus)\n",
    "\n",
    "# transform test articles into features\n",
    "tv_test_features = tv.transform(test_corpus)\n",
    "print('TFIDF model:> Train features shape:', tv_train_features.shape,' Test features shape:', tv_test_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now build several classifiers on these features using the training data and test\n",
    "their performance on the test dataset using all the classification models. We also check\n",
    "model accuracies using five-fold cross validation, just like we did earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.8743180578286961\n",
      "Test Accuracy: 0.7395691300790838\n"
     ]
    }
   ],
   "source": [
    "# Naïve Bayes\n",
    "mnb = MultinomialNB(alpha=1)\n",
    "mnb.fit(tv_train_features, train_label_names)\n",
    "\n",
    "mnb_tfidf_train_scores = mnb.score(tv_train_features, train_label_names)\n",
    "print('Train Accuracy:', mnb_tfidf_train_scores)\n",
    "\n",
    "mnb_tfidf_test_scores = mnb.score(tv_test_features, test_label_names)\n",
    "print('Test Accuracy:', mnb_tfidf_test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9955673758865248\n",
      "Test Accuracy: 0.7706572129806382\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machines\n",
    "svm = LinearSVC(penalty='l2', C=1, random_state=42)\n",
    "svm.fit(tv_train_features, train_label_names)\n",
    "\n",
    "svm_tfidf_train_scores = svm.score(tv_train_features, train_label_names)\n",
    "print('Train Accuracy:', svm_tfidf_train_scores)\n",
    "\n",
    "svm_tfidf_test_scores = svm.score(tv_test_features, test_label_names)\n",
    "print('Test Accuracy:', svm_tfidf_test_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now do a nice comparison of all the models we have tried so far with the two\n",
    "different feature engineering techniques. We will build a dataframe from our modeling\n",
    "results and compare the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>Linear SVM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Score (TF)</th>\n",
       "      <td>0.843426</td>\n",
       "      <td>0.997545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Score (TF)</th>\n",
       "      <td>0.702209</td>\n",
       "      <td>0.668666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Score (TF-IDF)</th>\n",
       "      <td>0.874318</td>\n",
       "      <td>0.995567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Score (TF-IDF)</th>\n",
       "      <td>0.739569</td>\n",
       "      <td>0.770657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                0           1\n",
       "Model                 Naive Bayes  Linear SVM\n",
       "Train Score (TF)         0.843426    0.997545\n",
       "Test Score (TF)          0.702209    0.668666\n",
       "Train Score (TF-IDF)     0.874318    0.995567\n",
       "Test Score (TF-IDF)      0.739569    0.770657"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([['Naive Bayes', mnb_bow_train_scores, mnb_bow_test_scores,\n",
    "               mnb_tfidf_train_scores, mnb_tfidf_test_scores],\n",
    "              ['Linear SVM', svm_bow_train_scores, svm_bow_test_scores,\n",
    "               svm_tfidf_train_scores, svm_tfidf_test_scores]\n",
    "              ],\n",
    "             columns=['Model', 'Train Score (TF)', 'Test Score (TF)','Train Score (TF-IDF)', 'Test Score (TF-IDF)'],).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
